{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'main'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1244137b3ee5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcrnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrnn_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRMNIST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMNIST\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'main'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../..')\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import func.models.crnn as crnn\n",
    "from rnn_dataset import RMNIST, MNIST\n",
    "from new_main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(in_channel = 1).cuda()\n",
    "model.eval()\n",
    "model_path = '/media/gaor2/46324cd9-d012-4189-b58d-54605a1828aa/saved_file/mnist/bl/model_epoch_0014.pth'\n",
    "model.load_state_dict(torch.load(model_pth))\n",
    "for batch_idx, (data, target) in enumerate(self.test_loader):  # no test_loader yet\n",
    "    data, target = data.to(self.device), target.to(self.device)\n",
    "    #self.optim.zero_grad()\n",
    "    pred = self.model(data)             # here should be careful\n",
    "    #loss = self.criterion(pred, target)\n",
    "    loss = LossPool(pred, target, self.cfig, loss_name=self.cfig['loss_name']).get_loss()\n",
    "    pred_cls = pred.data.max(1)[1]     # not test yet\n",
    "    pred_list+=pred_cls.data.cpu().numpy().tolist()\n",
    "    target_list+=target.data.cpu().numpy().tolist()\n",
    "    loss_list.append(loss.data.cpu().numpy().tolist())\n",
    "\n",
    "\n",
    "accuracy=accuracy_score(target_list,pred_list)\n",
    "print (accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_packed True\n",
      "input size torch.Size([4, 2, 14, 14, 18])\n",
      "w_ih torch.Size([5, 2, 3, 4, 6]) torch.Size([5, 5, 3, 4, 6])\n",
      "input shape torch.Size([2, 2, 14, 14, 18])\n",
      "w_ih torch.Size([5, 2, 3, 4, 6]) torch.Size([5, 5, 3, 4, 6])\n",
      "input shape torch.Size([1, 2, 14, 14, 18])\n",
      "w_ih torch.Size([5, 2, 3, 4, 6]) torch.Size([5, 5, 3, 4, 6])\n",
      "input shape torch.Size([1, 2, 14, 14, 18])\n",
      "w_ih torch.Size([5, 2, 3, 4, 6]) torch.Size([5, 5, 3, 4, 6])\n",
      "input shape torch.Size([1, 2, 14, 14, 18])\n",
      "w_ih torch.Size([5, 2, 3, 4, 6]) torch.Size([5, 5, 3, 4, 6])\n",
      "input shape torch.Size([1, 2, 14, 14, 18])\n",
      "w_ih torch.Size([5, 2, 3, 4, 6]) torch.Size([5, 5, 3, 4, 6])\n",
      "input shape torch.Size([2, 2, 14, 14, 18])\n",
      "w_ih torch.Size([5, 10, 3, 4, 6]) torch.Size([5, 5, 3, 4, 6])\n",
      "input shape torch.Size([2, 10, 14, 14, 18])\n",
      "w_ih torch.Size([5, 10, 3, 4, 6]) torch.Size([5, 5, 3, 4, 6])\n",
      "input shape torch.Size([1, 10, 14, 14, 18])\n",
      "w_ih torch.Size([5, 10, 3, 4, 6]) torch.Size([5, 5, 3, 4, 6])\n",
      "input shape torch.Size([1, 10, 14, 14, 18])\n",
      "w_ih torch.Size([5, 10, 3, 4, 6]) torch.Size([5, 5, 3, 4, 6])\n",
      "input shape torch.Size([1, 10, 14, 14, 18])\n",
      "w_ih torch.Size([5, 10, 3, 4, 6]) torch.Size([5, 5, 3, 4, 6])\n",
      "input shape torch.Size([1, 10, 14, 14, 18])\n",
      "w_ih torch.Size([5, 10, 3, 4, 6]) torch.Size([5, 5, 3, 4, 6])\n",
      "input shape torch.Size([2, 10, 14, 14, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local/VANDERBILT/gaor2/anaconda3/envs/python36/lib/python3.6/site-packages/torch/nn/functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "time = 3\n",
    "input = torch.randn(time, 2, 1, 32, 32)\n",
    "x = pack_padded_sequence(torch.randn(3, 2, 2, 14,14, 18), [3, 1])\n",
    "output = net(x)\n",
    "# output = []\n",
    "# for i in range(time):\n",
    "#     if i == 0:\n",
    "#         hx, cx = cell(input[i])\n",
    "#     else:\n",
    "#         hx, cx = cell(input[i], (hx, cx))\n",
    "#     output.append(hx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True} if True else {}\n",
    "dataset = datasets.MNIST('/share3/gaor2/share5backup/data/mnist', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ]))\n",
    "train_loader = torch.utils.data.DataLoader( dataset,\n",
    "batch_size=4, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "            datasets.MNIST('/share3/gaor2/share5backup/data/mnist', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "batch_size=4, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data = torch.load('/share3/gaor2/share5backup/data/mnist/processed/training.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "labels_1 = np.where(labels == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbs_dict = {}\n",
    "for i in range(10):\n",
    "    lbs_index = np.where(labels == i)\n",
    "    lbs_index = list(lbs_index[0])\n",
    "    lbs_dict[i] = lbs_index\n",
    "new_labellist = []\n",
    "data_matrix = []\n",
    "for i in range(10):\n",
    "    tmp_list = [i] * (len(lbs_dict[i]) // 3) \n",
    "    new_labellist += tmp_list\n",
    "    for j in range(len(lbs_dict[i]) // 3):\n",
    "        tmp = [lbs_dict[i][j * 3], lbs_dict[i][j * 3 + 1], lbs_dict[i][j * 3 + 2]]\n",
    "        data_matrix.append(tmp)\n",
    "new_data = torch.zeros((len(new_labellist), 3, 28, 28), dtype = torch.int8)\n",
    "for i in range(len(new_labellist)):\n",
    "    for j in range(3):\n",
    "        new_data[i,j, :, :] = data[data_matrix[i][j], :, :]\n",
    "new_label = torch.LongTensor(new_labellist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RMNIST('/share3/gaor2/share5backup/data/mnist', 3, train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ]))\n",
    "dataset2 = MNIST('/share3/gaor2/share5backup/data/mnist', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True} if True else {}\n",
    "train_loader = torch.utils.data.DataLoader( dataset,\n",
    "                 batch_size= 4, shuffle=True, **kwargs)\n",
    "train_loader2 = torch.utils.data.DataLoader( dataset2,\n",
    "                 batch_size= 4, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n",
      "tmp type torch.uint8\n",
      "tmp type torch.uint8\n",
      "tmp type torch.uint8\n",
      "torch.Size([3, 28, 28])\n",
      "tmp type torch.uint8\n",
      "tmp type torch.uint8\n",
      "tmp type torch.uint8\n",
      "torch.Size([3, 28, 28])\n",
      "tmp type torch.uint8\n",
      "tmp type torch.uint8\n",
      "tmp type torch.uint8\n",
      "torch.Size([3, 28, 28])\n",
      "tmp type torch.uint8\n",
      "tmp type torch.uint8\n",
      "tmp type torch.uint8\n",
      "torch.Size([3, 28, 28])\n",
      "tmp type torch.uint8\n",
      "tmp type torch.uint8\n",
      "tmp type torch.uint8\n",
      "torch.Size([3, 28, 28])\n",
      "tmp type torch.uint8\n",
      "tmp type torch.uint8\n",
      "tmp type torch.uint8\n",
      "torch.Size([3, 28, 28])\n",
      "tmp type torch.uint8\n",
      "tmp type torch.uint8\n",
      "tmp type torch.uint8\n",
      "torch.Size([3, 28, 28])\n",
      "tmp type torch.uint8\n",
      "tmp type torch.uint8\n",
      "tmp type torch.uint8\n",
      "torch.Size([3, 28, 28])\n",
      "tmp type torch.uint8\n",
      "Labels:  tensor([1, 2, 2, 1])\n",
      "Batch shape:  torch.Size([4, 3, 1, 28, 28])\n",
      "tmp type torch.uint8\n",
      "tmp type torch.uint8\n",
      "torch.Size([3, 28, 28])\n",
      "tmp type torch.uint8\n",
      "tmp type torch.uint8\n",
      "tmp type torch.uint8\n",
      "torch.Size([3, 28, 28])\n",
      "tmp type torch.uint8\n",
      "tmp type torch.uint8\n",
      "tmp type torch.uint8\n",
      "torch.Size([3, 28, 28])\n",
      "tmp type torch.uint8\n",
      "tmp type torch.uint8\n",
      "tmp type torch.uint8\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "print('Labels: ', labels)\n",
    "print('Batch shape: ', images.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python36]",
   "language": "python",
   "name": "conda-env-python36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
